{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41a0c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# from collections import deque\n",
    "import numpy as np\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8a571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 'FrankaKitchen-v1'\n",
    "task = 'kettle'\n",
    "gym.register_envs(gymnasium_robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2769def",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2c4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim = 73\n",
    "obs_low = np.full((flat_dim,), -1e10, dtype=np.float32)\n",
    "obs_high = np.full((flat_dim,), 1e10, dtype=np.float32)\n",
    "\n",
    "class FlattenDictWrapper(gym.ObservationWrapper):    \n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.keys = env.observation_space.spaces.keys()\n",
    "        self.observation_space = gym.spaces.Box(low=obs_low, high=obs_high, shape=(flat_dim,), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        achieved = observation['achieved_goal'][task].astype(np.float32)\n",
    "        desired = observation['desired_goal'][task].astype(np.float32)\n",
    "        obs = observation['observation'].astype(np.float32)\n",
    "\n",
    "        flat_obs = np.concatenate([achieved, desired, obs], dtype=np.float32)\n",
    "        return flat_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93560185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    env = gym.make(env_id, render_mode=None, tasks_to_complete=[task])  # Or your actual task\n",
    "    env = FlattenDictWrapper(env)\n",
    "    return env\n",
    "\n",
    "n_training_envs = 64\n",
    "env = DummyVecEnv([make_env]*n_training_envs)\n",
    "eval_env = DummyVecEnv([make_env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a85f96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_timesteps = 250000\n",
    "run_name = f\"ddpg_{max_timesteps}_\"+task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d44c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_log_dir = os.path.join(\"eval_logs\", run_name)\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=eval_log_dir,\n",
    "                              log_path=eval_log_dir, eval_freq=max(500 // n_training_envs, 1),\n",
    "                              n_eval_episodes=5, deterministic=True,\n",
    "                              render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7db8869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/repos/rl/rl-value-based/venv/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 3.14GB > 1.35GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The noise objects for DDPG\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1, device=device, buffer_size=5000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f00759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=max_timesteps, log_interval=10, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "616f8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n",
      "Episode reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\tenv_eval = make_env()\n",
    "\tobs, _ = env_eval.reset()\n",
    "\tdone = False\n",
    "\tep_reward = 0\n",
    "\n",
    "\twhile not done:\n",
    "\t\taction, _ = model.predict(obs, deterministic=True)\n",
    "\t\tobs, reward, terminated, truncated, _ = env_eval.step(action)\n",
    "\t\tdone = terminated or truncated\n",
    "\t\tep_reward += reward\n",
    "\tprint(f\"Episode reward: {ep_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Box(-1.0, 1.0, (9,), float64)\n",
      "Model action space: Box(-1.0, 1.0, (9,), float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env_eval.action_space)\n",
    "print(\"Model action space:\", model.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d0edd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

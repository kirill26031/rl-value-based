{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41a0c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium_robotics\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# from collections import deque\n",
    "import numpy as np\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f8a571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = 'FrankaKitchen-v1'\n",
    "task = 'kettle'\n",
    "gym.register_envs(gymnasium_robotics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2769def",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b2c4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim = 73\n",
    "obs_low = np.full((flat_dim,), -1e10, dtype=np.float32)\n",
    "obs_high = np.full((flat_dim,), 1e10, dtype=np.float32)\n",
    "\n",
    "class FlattenDictWrapper(gym.ObservationWrapper):    \n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.keys = env.observation_space.spaces.keys()\n",
    "        self.observation_space = gym.spaces.Box(low=obs_low, high=obs_high, shape=(flat_dim,), dtype=np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        achieved = observation['achieved_goal'][task].astype(np.float32)\n",
    "        desired = observation['desired_goal'][task].astype(np.float32)\n",
    "        obs = observation['observation'].astype(np.float32)\n",
    "\n",
    "        flat_obs = np.concatenate([achieved, desired, obs], dtype=np.float32)\n",
    "        return flat_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88b7b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"MUJOCO_MODEL_PATH\"] = \"c:\\\\Users\\\\pc\\\\Documents\\\\repos\\\\Gymnasium-Robotics\\\\gymnasium_robotics\\\\envs\\\\assets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93560185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n"
     ]
    }
   ],
   "source": [
    "def make_env():\n",
    "    env = gym.make(env_id, render_mode=None, tasks_to_complete=[task])  # Or your actual task\n",
    "    env = FlattenDictWrapper(env)\n",
    "    return env\n",
    "\n",
    "env = DummyVecEnv([make_env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db8869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n",
      "Box(-10000000000.0, 10000000000.0, (73,), float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The noise objects for DDPG\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1, device=device, buffer_size=5000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f00759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.learn(total_timesteps=100000, log_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaf5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"ddpg_\"+task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d3e73e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-10000000000.0, 10000000000.0, (73,), float32)\n"
     ]
    }
   ],
   "source": [
    "# vec_env = model.get_env()\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DDPG.load(\"ddpg_\"+task)\n",
    "\n",
    "# obs = vec_env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ee8b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# success = False\n",
    "# run_counter = 0\n",
    "# while not success:\n",
    "# \tvec_env.reset()\n",
    "# \tdone = False\n",
    "# \tcounter = 0\n",
    "# \twhile not done:\n",
    "# \t\taction, _states = model.predict(obs)\n",
    "# \t\tobs, rewards, dones, info = vec_env.step(action)\n",
    "# \t\tdone = dones[0]\n",
    "# \t\tcounter += 1\n",
    "# \tif counter != 280:\n",
    "# \t\tsuccess = True\n",
    "# \trun_counter += 1\n",
    "# \tprint(success, run_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616f8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n",
      "Episode reward: 0.0\n",
      "C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: resource not found via provider or OS filesystem: 'C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\assets\\kitchen_franka\\franka_assets\\meshes\\collision\\link0.stl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m \tenv_eval \u001b[38;5;241m=\u001b[39m make_env()\n\u001b[0;32m      3\u001b[0m \tobs, _ \u001b[38;5;241m=\u001b[39m env_eval\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      4\u001b[0m \tdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36mmake_env\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_env\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(env_id, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tasks_to_complete\u001b[38;5;241m=\u001b[39m[task])  \u001b[38;5;66;03m# Or your actual task\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     env \u001b[38;5;241m=\u001b[39m FlattenDictWrapper(env)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\n",
      "File \u001b[1;32mc:\\Users\\pc\\.conda\\envs\\rl\\Lib\\site-packages\\gymnasium\\envs\\registration.py:742\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    737\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment is being initialised with render_mode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_mode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat is not in the possible render_modes (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_modes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m         )\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 742\u001b[0m     env \u001b[38;5;241m=\u001b[39m env_creator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39menv_spec_kwargs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    745\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrender_mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    746\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m apply_human_rendering\n\u001b[0;32m    747\u001b[0m     ):\n",
      "File \u001b[1;32m~\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\kitchen_env.py:241\u001b[0m, in \u001b[0;36mKitchenEnv.__init__\u001b[1;34m(self, tasks_to_complete, terminate_on_tasks_completed, remove_task_when_completed, object_noise_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    235\u001b[0m     tasks_to_complete: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist[str]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(OBS_ELEMENT_GOALS\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    240\u001b[0m ):\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot_env \u001b[38;5;241m=\u001b[39m FrankaRobot(\n\u001b[0;32m    242\u001b[0m         model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../assets/kitchen_franka/kitchen_assets/kitchen_env_model.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot_env\u001b[38;5;241m.\u001b[39minit_qpos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    247\u001b[0m         [\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;241m1.48388023e-01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m         ]\n\u001b[0;32m    279\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot_env\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[1;32m~\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\franka_kitchen\\franka_env.py:70\u001b[0m, in \u001b[0;36mFrankaRobot.__init__\u001b[1;34m(self, model_path, frame_skip, robot_noise_ratio, default_camera_config, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobot_noise_ratio \u001b[38;5;241m=\u001b[39m robot_noise_ratio\n\u001b[0;32m     66\u001b[0m observation_space \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     67\u001b[0m     spaces\u001b[38;5;241m.\u001b[39mBox(low\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, high\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[0;32m     68\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     71\u001b[0m     xml_file_path,\n\u001b[0;32m     72\u001b[0m     frame_skip,\n\u001b[0;32m     73\u001b[0m     observation_space,\n\u001b[0;32m     74\u001b[0m     default_camera_config\u001b[38;5;241m=\u001b[39mdefault_camera_config,\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     76\u001b[0m )\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_qpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_qvel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqvel\n",
      "File \u001b[1;32mc:\\Users\\pc\\.conda\\envs\\rl\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:79\u001b[0m, in \u001b[0;36mMujocoEnv.__init__\u001b[1;34m(self, model_path, frame_skip, observation_space, render_mode, width, height, camera_id, camera_name, default_camera_config, max_geom, visual_options)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# may use width and height\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_simulation()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_qpos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqpos\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_qvel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mqvel\u001b[38;5;241m.\u001b[39mravel()\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\pc\\.conda\\envs\\rl\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:124\u001b[0m, in \u001b[0;36mMujocoEnv._initialize_simulation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_simulation\u001b[39m(\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmujoco.MjModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmujoco.MjData\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Initialize MuJoCo simulation data structures `mjModel` and `mjData`.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     model \u001b[38;5;241m=\u001b[39m mujoco\u001b[38;5;241m.\u001b[39mMjModel\u001b[38;5;241m.\u001b[39mfrom_xml_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullpath)\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# MjrContext will copy model.vis.global_.off* to con.off*\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     model\u001b[38;5;241m.\u001b[39mvis\u001b[38;5;241m.\u001b[39mglobal_\u001b[38;5;241m.\u001b[39moffwidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\n",
      "\u001b[1;31mValueError\u001b[0m: Error: resource not found via provider or OS filesystem: 'C:\\Users\\pc\\Documents\\repos\\Gymnasium-Robotics\\gymnasium_robotics\\envs\\assets\\kitchen_franka\\franka_assets\\meshes\\collision\\link0.stl'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\tenv_eval = make_env()\n",
    "\tobs, _ = env_eval.reset()\n",
    "\tdone = False\n",
    "\tep_reward = 0\n",
    "\n",
    "\twhile not done:\n",
    "\t\taction, _ = model.predict(obs, deterministic=True)\n",
    "\t\tobs, reward, terminated, truncated, _ = env_eval.step(action)\n",
    "\t\tdone = terminated or truncated\n",
    "\t\tep_reward += reward\n",
    "\tprint(f\"Episode reward: {ep_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Box(-1.0, 1.0, (9,), float64)\n",
      "Model action space: Box(-1.0, 1.0, (9,), float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space:\", env_eval.action_space)\n",
    "print(\"Model action space:\", model.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d0edd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
